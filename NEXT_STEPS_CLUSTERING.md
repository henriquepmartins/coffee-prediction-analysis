# üìä Pr√≥ximos Passos: Modelo de Clusteriza√ß√£o

## üìã Contexto do Projeto

Este projeto visa prever e agrupar padr√µes de consumo de caf√© baseado em caracter√≠sticas temporais, clim√°ticas e de pagamento. Atualmente, temos:

### ‚úÖ **O que j√° foi feito:**

1. **An√°lise Explorat√≥ria de Dados (EDA)**
   - Notebook: `notebooks/01_exploratory_data_analysis.ipynb`
   - Limpeza e prepara√ß√£o dos dados
   - Cria√ß√£o de features temporais e clim√°ticas
   - Exporta√ß√£o para `data/coffee_cleaned.csv`

2. **Modelo de Classifica√ß√£o**
   - Notebook: `notebooks/02_model_training.ipynb`
   - Classifica√ß√£o bin√°ria: "Cafe Preto" vs "Leite e Doces"
   - XGBoost com otimiza√ß√£o de hiperpar√¢metros
   - Accuracy: ~67% | Balanced Accuracy: ~58%
   - Features utilizadas: tempo, clima, per√≠odo do dia, intera√ß√µes

---

## üéØ Objetivo da Clusteriza√ß√£o

Identificar **padr√µes de comportamento** nos clientes/compras sem usar labels pr√©-definidos. A clusteriza√ß√£o deve revelar:

- **Grupos de clientes** com comportamentos similares
- **Padr√µes temporais** de consumo (hor√°rios, dias da semana)
- **Perfis de prefer√™ncia** (caf√© puro vs bebidas com leite)
- **Segmenta√ß√£o** para estrat√©gias de marketing personalizadas

---

## üìÅ Estrutura do Projeto

```
coffee-prediction/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ coffee_cleaned.csv          # Dataset limpo e processado
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploratory_data_analysis.ipynb  # EDA completo
‚îÇ   ‚îú‚îÄ‚îÄ 02_model_training.ipynb             # Classifica√ß√£o (conclu√≠do)
‚îÇ   ‚îî‚îÄ‚îÄ 03_clustering.ipynb                  # ‚ö†Ô∏è A CRIAR
‚îî‚îÄ‚îÄ coffee-venv/                    # Ambiente virtual Python
```

---

## üìä Dados Dispon√≠veis

### **Dataset:** `data/coffee_cleaned.csv`

**Colunas principais:**
- `datetime`: Data e hora da compra
- `coffee_name`: Nome do caf√© (8 tipos)
- `hour_float_30min`: Hora em formato decimal (0-24)
- `day_of_week`: Dia da semana (0=Segunda, 6=Domingo)
- `month`: M√™s (1-12)
- `weather`: Condi√ß√£o clim√°tica (sol, chuva, nublado, frio)
- `cash_type`: Tipo de pagamento

**Features j√° criadas (dispon√≠veis no EDA):**
- `hour_sin`, `hour_cos`: Encoding c√≠clico da hora
- `is_weekend`: Bin√°rio (fim de semana)
- `is_morning`, `is_afternoon`, `is_evening`: Per√≠odos do dia
- `morning_cold`, `evening_cold`, `weekend_morning`: Intera√ß√µes

**Total de registros:** ~3,638 transa√ß√µes

---

## üîß Tarefas para o Modelo de Clusteriza√ß√£o

### **1. Prepara√ß√£o dos Dados**

```python
# Carregar dados
df = pd.read_csv("data/coffee_cleaned.csv")
df["datetime"] = pd.to_datetime(df["datetime"])

# Decidir quais features usar para clusteriza√ß√£o
# Op√ß√µes:
# A) Features temporais + clima (sem target)
# B) Features + comportamento de compra (frequ√™ncia, valor m√©dio)
# C) Features + hist√≥rico de prefer√™ncias
```

**Decis√µes necess√°rias:**
- [ ] Incluir ou excluir `coffee_name` como feature?
- [ ] Criar features agregadas por cliente? (se houver ID de cliente)
- [ ] Normalizar/escalar features num√©ricas
- [ ] Tratar features categ√≥ricas (OneHotEncoder ou LabelEncoder)

---

### **2. Escolha do Algoritmo**

**Op√ß√µes recomendadas:**

#### **A) K-Means** (Mais simples)
- ‚úÖ R√°pido e interpret√°vel
- ‚úÖ Bom para dados num√©ricos
- ‚ö†Ô∏è Requer n√∫mero de clusters pr√©-definido
- ‚ö†Ô∏è Sens√≠vel a outliers

#### **B) DBSCAN** (Densidade)
- ‚úÖ N√£o precisa definir n√∫mero de clusters
- ‚úÖ Identifica outliers automaticamente
- ‚ö†Ô∏è Mais complexo de ajustar (eps, min_samples)

#### **C) Hierarchical Clustering** (Agrupamento hier√°rquico)
- ‚úÖ Visualiza√ß√£o com dendrograma
- ‚úÖ N√£o precisa definir K inicialmente
- ‚ö†Ô∏è Computacionalmente caro para datasets grandes

#### **D) Gaussian Mixture Models (GMM)**
- ‚úÖ Probabil√≠stico (soft clustering)
- ‚úÖ Lida bem com clusters de formas diferentes
- ‚ö†Ô∏è Mais complexo

**Recomenda√ß√£o inicial:** Come√ßar com **K-Means** e depois testar **DBSCAN** se necess√°rio.

---

### **3. Determina√ß√£o do N√∫mero de Clusters**

**M√©tricas a usar:**

1. **Elbow Method** (M√©todo do Cotovelo)
   - Plotar in√©rcia vs n√∫mero de clusters
   - Identificar o "cotovelo" no gr√°fico

2. **Silhouette Score**
   - Mede qu√£o bem separados est√£o os clusters
   - Valores entre -1 e 1 (quanto maior, melhor)
   - Plotar silhouette score vs n√∫mero de clusters

3. **Gap Statistic**
   - Compara in√©rcia real vs in√©rcia esperada
   - Mais robusto que Elbow Method

**C√≥digo exemplo:**
```python
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Testar diferentes valores de K
k_range = range(2, 11)
inertias = []
silhouette_scores = []

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X_scaled)
    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_scaled, labels))

# Plotar resultados
```

---

### **4. Visualiza√ß√£o dos Clusters**

**Gr√°ficos essenciais:**

1. **PCA/T-SNE para redu√ß√£o de dimensionalidade**
   ```python
   from sklearn.decomposition import PCA
   from sklearn.manifold import TSNE
   
   # Reduzir para 2D para visualiza√ß√£o
   pca = PCA(n_components=2)
   X_pca = pca.fit_transform(X_scaled)
   
   # Plotar clusters em 2D
   plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis')
   ```

2. **An√°lise de caracter√≠sticas por cluster**
   - Boxplots das features mais importantes por cluster
   - Heatmap de m√©dias de features por cluster
   - Distribui√ß√£o de `coffee_name` por cluster

3. **An√°lise temporal**
   - Distribui√ß√£o de hor√°rios por cluster
   - Distribui√ß√£o de dias da semana por cluster
   - Padr√µes de clima por cluster

---

### **5. Interpreta√ß√£o e Valida√ß√£o**

**Perguntas a responder:**

- [ ] Cada cluster representa um perfil distinto de cliente?
- [ ] Os clusters fazem sentido do ponto de vista de neg√≥cio?
- [ ] H√° clusters que s√£o claramente "Cafe Preto" vs "Leite e Doces"?
- [ ] Existem padr√µes temporais espec√≠ficos por cluster?
- [ ] Os clusters s√£o est√°veis? (testar com diferentes seeds)

**Valida√ß√£o:**
- Comparar clusters com labels conhecidos (se dispon√≠vel)
- An√°lise de features mais discriminantes por cluster
- Teste de estabilidade (rodar m√∫ltiplas vezes com diferentes seeds)

---

## üìù Estrutura Sugerida do Notebook `03_clustering.ipynb`

### **C√©lula 1: Imports**
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, silhouette_samples
```

### **C√©lula 2: Carregamento e Prepara√ß√£o**
- Carregar `coffee_cleaned.csv`
- Selecionar features para clusteriza√ß√£o
- Escalar/normalizar dados

### **C√©lula 3: An√°lise Explorat√≥ria**
- Estat√≠sticas descritivas
- Correla√ß√µes entre features
- Visualiza√ß√µes iniciais

### **C√©lula 4: Determina√ß√£o do N√∫mero de Clusters**
- Elbow Method
- Silhouette Analysis
- Decis√£o do K √≥timo

### **C√©lula 5: Treinamento do Modelo**
- K-Means (ou outro algoritmo escolhido)
- Ajuste de hiperpar√¢metros

### **C√©lula 6: Visualiza√ß√£o dos Clusters**
- PCA/T-SNE 2D
- An√°lise de caracter√≠sticas por cluster
- Gr√°ficos de distribui√ß√£o

### **C√©lula 7: Interpreta√ß√£o**
- Perfis de cada cluster
- An√°lise de neg√≥cio
- Insights e recomenda√ß√µes

---

## üéØ Objetivos de Neg√≥cio

A clusteriza√ß√£o deve ajudar a responder:

1. **Segmenta√ß√£o de Clientes**
   - Quais s√£o os principais perfis de consumidores?
   - Como personalizar ofertas para cada segmento?

2. **Otimiza√ß√£o de Opera√ß√µes**
   - Quais hor√°rios t√™m padr√µes similares?
   - Como preparar estoque baseado em clusters?

3. **Marketing**
   - Quais clusters respondem melhor a promo√ß√µes?
   - Como criar campanhas segmentadas?

---

## üîó Refer√™ncias √öteis

- **Scikit-learn Clustering:** https://scikit-learn.org/stable/modules/clustering.html
- **K-Means:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
- **DBSCAN:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html
- **Silhouette Analysis:** https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html

---

## ‚ö†Ô∏è Pontos de Aten√ß√£o

1. **Escalonamento:** Sempre escalar features num√©ricas antes de clusterizar (StandardScaler)
2. **Features Categ√≥ricas:** Decidir se usar OneHotEncoder ou outra estrat√©gia
3. **Dimensionalidade:** Considerar PCA se houver muitas features
4. **Interpretabilidade:** Priorizar clusters que fa√ßam sentido de neg√≥cio
5. **Valida√ß√£o:** Testar estabilidade dos clusters com diferentes seeds

---

## üìå Checklist para Iniciar

- [ ] Ler este documento completamente
- [ ] Revisar `notebooks/01_exploratory_data_analysis.ipynb` para entender os dados
- [ ] Revisar `notebooks/02_model_training.ipynb` para ver features criadas
- [ ] Carregar `data/coffee_cleaned.csv` e explorar estrutura
- [ ] Decidir quais features usar para clusteriza√ß√£o
- [ ] Criar notebook `03_clustering.ipynb`
- [ ] Come√ßar com K-Means e Elbow Method
- [ ] Validar resultados com Silhouette Score
- [ ] Visualizar e interpretar clusters

---

**Boa sorte com a clusteriza√ß√£o! üöÄ‚òï**

*√öltima atualiza√ß√£o: Baseado no estado do projeto ap√≥s conclus√£o do modelo de classifica√ß√£o.*

